{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0436c56e",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/YichenShen0103/CUMCM-25C/blob/main/problem4.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "04545b90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x138d6fad0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, PowerTransformer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# 设置随机种子\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ea57f1dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "原始数据集形状: (604, 20)\n",
      "类别分布: class\n",
      "0    537\n",
      "1     67\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# 读取数据\n",
    "url = \"https://raw.githubusercontent.com/YichenShen0103/CUMCM-25C/main/data/data.xlsx\"\n",
    "data = pd.read_excel(url, sheet_name=1)\n",
    "data[\"class\"] = data[\"染色体的非整倍体\"].notna().astype(int)\n",
    "weeks_days = data[\"检测孕周\"].str.split(r\"[wW]\", expand=True)\n",
    "data[\"孕天\"] = weeks_days[0].astype(int) * 7 + weeks_days[1].fillna(\"0\").replace(\n",
    "    \"\", \"0\"\n",
    ").astype(int)\n",
    "data.drop(\"检测孕周\", axis=1, inplace=True)\n",
    "\n",
    "useless_columns = [\n",
    "    \"Unnamed: 20\",\n",
    "    \"Unnamed: 21\",\n",
    "    \"序号\",\n",
    "    \"孕妇代码\",\n",
    "    \"末次月经\",\n",
    "    \"检测日期\",\n",
    "    \"末次月经\",\n",
    "    \"胎儿是否健康\",\n",
    "    \"染色体的非整倍体\",\n",
    "    \"IVF妊娠\",\n",
    "    \"怀孕次数\",\n",
    "    \"检测抽血次数\",\n",
    "]\n",
    "data.drop(columns=useless_columns, inplace=True)\n",
    "data.dropna(inplace=True)\n",
    "\n",
    "X = data.drop(columns=[\"class\"])\n",
    "y = data[\"class\"]\n",
    "\n",
    "print(f\"原始数据集形状: {X.shape}\")\n",
    "print(f\"类别分布: {y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1241c559",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "特征工程后形状: (604, 98)\n",
      "训练集形状: (513, 98)\n",
      "测试集形状: (91, 98)\n"
     ]
    }
   ],
   "source": [
    "# 特征工程\n",
    "def create_advanced_features(X):\n",
    "    X_new = X.copy()\n",
    "\n",
    "    # 添加特征交互\n",
    "    feature_names = X.columns.tolist()\n",
    "    for i in range(len(feature_names)):\n",
    "        for j in range(i + 1, min(i + 5, len(feature_names))):  # 限制交互数量\n",
    "            X_new[f\"{feature_names[i]}_{feature_names[j]}_interaction\"] = (\n",
    "                X.iloc[:, i] * X.iloc[:, j]\n",
    "            )\n",
    "\n",
    "    # 添加多项式特征（选择重要特征）\n",
    "    important_features = [\"年龄\", \"孕天\", \"AFP_MOM\", \"Free_HCG_MOM\", \"Inhibin_A_MOM\"]\n",
    "    for feat in important_features:\n",
    "        if feat in X.columns:\n",
    "            X_new[f\"{feat}_squared\"] = X[feat] ** 2\n",
    "            X_new[f\"{feat}_log\"] = np.log1p(np.abs(X[feat]))\n",
    "\n",
    "    # 添加统计特征\n",
    "    X_new[\"feature_sum\"] = X.sum(axis=1)\n",
    "    X_new[\"feature_mean\"] = X.mean(axis=1)\n",
    "    X_new[\"feature_std\"] = X.std(axis=1)\n",
    "    X_new[\"feature_skew\"] = X.skew(axis=1)\n",
    "\n",
    "    return X_new\n",
    "\n",
    "\n",
    "# 应用特征工程\n",
    "X_engineered = create_advanced_features(X)\n",
    "print(f\"特征工程后形状: {X_engineered.shape}\")\n",
    "\n",
    "# 使用PowerTransformer处理偏斜分布\n",
    "transformer = PowerTransformer(method=\"yeo-johnson\")\n",
    "X_transformed = transformer.fit_transform(X_engineered)\n",
    "\n",
    "# 标准化\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_transformed)\n",
    "\n",
    "# 数据分割\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.15, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"训练集形状: {X_train.shape}\")\n",
    "print(f\"测试集形状: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51da59d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 神经网络\n",
    "class SuperAdvancedClassifier(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SuperAdvancedClassifier, self).__init__()\n",
    "\n",
    "        # 多分支架构\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 512),\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "        )\n",
    "\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Linear(input_dim, 256),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3),\n",
    "        )\n",
    "\n",
    "        # 注意力机制\n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Linear(256 + 128, 64), nn.Tanh(), nn.Linear(64, 1), nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # 最终分类器\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(256 + 128, 128),\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.BatchNorm1d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(64, 1),\n",
    "        )\n",
    "\n",
    "        self.apply(self._init_weights)\n",
    "\n",
    "    def _init_weights(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            nn.init.kaiming_uniform_(m.weight, nonlinearity=\"relu\")\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        b1 = self.branch1(x)\n",
    "        b2 = self.branch2(x)\n",
    "\n",
    "        # 合并分支\n",
    "        combined = torch.cat([b1, b2], dim=1)\n",
    "\n",
    "        # 注意力权重\n",
    "        attention_weights = self.attention(combined)\n",
    "        attended = combined * attention_weights\n",
    "\n",
    "        # 最终预测\n",
    "        output = self.classifier(attended)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2de756ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "数据增强后训练集形状: (741, 98)\n",
      "数据增强后类别分布: (array([0, 1]), array([456, 285]))\n"
     ]
    }
   ],
   "source": [
    "# 数据增强函数\n",
    "def augment_minority_class(X, y, augment_factor=3):\n",
    "    \"\"\"通过添加噪声来增强少数类样本\"\"\"\n",
    "    minority_indices = np.where(y == 1)[0]\n",
    "    minority_X = X[minority_indices]\n",
    "\n",
    "    augmented_X = []\n",
    "    augmented_y = []\n",
    "\n",
    "    for _ in range(augment_factor):\n",
    "        # 添加高斯噪声\n",
    "        noise = np.random.normal(0, 0.1, minority_X.shape)\n",
    "        augmented_samples = minority_X + noise\n",
    "        augmented_X.append(augmented_samples)\n",
    "        augmented_y.extend([1] * len(minority_X))\n",
    "\n",
    "    # 合并原始数据和增强数据\n",
    "    X_augmented = np.vstack([X] + augmented_X)\n",
    "    y_augmented = np.hstack([y, augmented_y])\n",
    "\n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "\n",
    "# 应用数据增强\n",
    "X_train_aug, y_train_aug = augment_minority_class(\n",
    "    X_train, y_train.values, augment_factor=4\n",
    ")\n",
    "print(f\"数据增强后训练集形状: {X_train_aug.shape}\")\n",
    "print(f\"数据增强后类别分布: {np.unique(y_train_aug, return_counts=True)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ebfca9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 训练超级神经网络 ===\n",
      "Epoch [100/15000], Loss: 0.0074, Test Accuracy: 92.31% (threshold: 0.70), Best: 92.31%\n",
      "Epoch [200/15000], Loss: 0.0017, Test Accuracy: 93.41% (threshold: 0.70), Best: 93.41%\n",
      "Epoch [300/15000], Loss: 0.0010, Test Accuracy: 93.41% (threshold: 0.70), Best: 93.41%\n",
      "Epoch [400/15000], Loss: 0.0005, Test Accuracy: 93.41% (threshold: 0.55), Best: 93.41%\n",
      "Epoch [500/15000], Loss: 0.0002, Test Accuracy: 94.51% (threshold: 0.75), Best: 94.51%\n",
      "Epoch [600/15000], Loss: 0.0001, Test Accuracy: 91.21% (threshold: 0.60), Best: 94.51%\n",
      "Epoch [700/15000], Loss: 0.0017, Test Accuracy: 92.31% (threshold: 0.75), Best: 94.51%\n",
      "Epoch [800/15000], Loss: 0.0002, Test Accuracy: 90.11% (threshold: 0.45), Best: 94.51%\n",
      "Epoch [900/15000], Loss: 0.0004, Test Accuracy: 92.31% (threshold: 0.60), Best: 94.51%\n",
      "Epoch [1000/15000], Loss: 0.0003, Test Accuracy: 92.31% (threshold: 0.60), Best: 94.51%\n",
      "Epoch [1100/15000], Loss: 0.0001, Test Accuracy: 91.21% (threshold: 0.55), Best: 94.51%\n",
      "Epoch [1200/15000], Loss: 0.0001, Test Accuracy: 91.21% (threshold: 0.70), Best: 94.51%\n",
      "Epoch [1300/15000], Loss: 0.0001, Test Accuracy: 91.21% (threshold: 0.75), Best: 94.51%\n",
      "Epoch [1400/15000], Loss: 0.0001, Test Accuracy: 89.01% (threshold: 0.70), Best: 94.51%\n",
      "Epoch [1500/15000], Loss: 0.0000, Test Accuracy: 91.21% (threshold: 0.70), Best: 94.51%\n",
      "Early stopping at epoch 1500\n"
     ]
    }
   ],
   "source": [
    "# 训练超级模型\n",
    "def train_super_model():\n",
    "    # 转换为张量\n",
    "    X_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train_aug, dtype=torch.float32).view(-1, 1)\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    # 创建数据加载器\n",
    "    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "\n",
    "    # 创建模型\n",
    "    model = SuperAdvancedClassifier(X_train_tensor.shape[1])\n",
    "\n",
    "    # 自适应损失函数\n",
    "    class AdaptiveFocalLoss(nn.Module):\n",
    "        def __init__(self, alpha=2, gamma=3):\n",
    "            super(AdaptiveFocalLoss, self).__init__()\n",
    "            self.alpha = alpha\n",
    "            self.gamma = gamma\n",
    "\n",
    "        def forward(self, inputs, targets):\n",
    "            BCE_loss = F.binary_cross_entropy_with_logits(\n",
    "                inputs, targets, reduction=\"none\"\n",
    "            )\n",
    "            pt = torch.exp(-BCE_loss)\n",
    "\n",
    "            # 动态调整alpha\n",
    "            pos_weight = (targets == 0).sum().float() / (targets == 1).sum().float()\n",
    "            alpha = torch.where(targets == 1, pos_weight, 1.0)\n",
    "\n",
    "            F_loss = alpha * (1 - pt) ** self.gamma * BCE_loss\n",
    "            return F_loss.mean()\n",
    "\n",
    "    criterion = AdaptiveFocalLoss(alpha=3, gamma=4)\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-3)\n",
    "\n",
    "    # 学习率调度器\n",
    "    scheduler = torch.optim.lr_scheduler.OneCycleLR(\n",
    "        optimizer, max_lr=0.01, epochs=15000, steps_per_epoch=len(train_loader)\n",
    "    )\n",
    "\n",
    "    best_accuracy = 0\n",
    "    best_model_state = None\n",
    "    patience_counter = 0\n",
    "    patience = 1000\n",
    "\n",
    "    for epoch in range(15000):\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "\n",
    "        for batch_X, batch_y in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(batch_X)\n",
    "            loss = criterion(outputs, batch_y)\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=0.5)\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        # 验证\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                test_outputs = model(X_test_tensor)\n",
    "                predicted_probs = torch.sigmoid(test_outputs)\n",
    "\n",
    "                # 动态阈值优化\n",
    "                thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "                best_threshold = 0.5\n",
    "                best_acc = 0\n",
    "\n",
    "                for threshold in thresholds:\n",
    "                    predicted = (predicted_probs >= threshold).float()\n",
    "                    acc = (\n",
    "                        (predicted.squeeze() == y_test_tensor.squeeze()).sum().item()\n",
    "                        / len(y_test)\n",
    "                        * 100\n",
    "                    )\n",
    "                    if acc > best_acc:\n",
    "                        best_acc = acc\n",
    "                        best_threshold = threshold\n",
    "\n",
    "                if best_acc > best_accuracy:\n",
    "                    best_accuracy = best_acc\n",
    "                    best_model_state = model.state_dict().copy()\n",
    "                    patience_counter = 0\n",
    "                else:\n",
    "                    patience_counter += 100\n",
    "\n",
    "                print(\n",
    "                    f\"Epoch [{epoch+1}/15000], Loss: {total_loss/len(train_loader):.4f}, \"\n",
    "                    f\"Test Accuracy: {best_acc:.2f}% (threshold: {best_threshold:.2f}), \"\n",
    "                    f\"Best: {best_accuracy:.2f}%\"\n",
    "                )\n",
    "\n",
    "                if patience_counter >= patience:\n",
    "                    print(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "\n",
    "    # 加载最佳模型\n",
    "    if best_model_state is not None:\n",
    "        model.load_state_dict(best_model_state)\n",
    "        torch.save(best_model_state, \"model/best_model.pth\")\n",
    "\n",
    "    return model, best_accuracy\n",
    "\n",
    "\n",
    "# 运行神经网络训练和评估\n",
    "print(\"\\n=== 训练超级神经网络 ===\")\n",
    "nn_model, nn_accuracy = train_super_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b809531",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== 评估保存的最佳模型 ===\n",
      "Threshold: 0.30, Accuracy: 83.52%\n",
      "Threshold: 0.35, Accuracy: 84.62%\n",
      "Threshold: 0.40, Accuracy: 85.71%\n",
      "Threshold: 0.45, Accuracy: 85.71%\n",
      "Threshold: 0.50, Accuracy: 87.91%\n",
      "Threshold: 0.55, Accuracy: 89.01%\n",
      "Threshold: 0.60, Accuracy: 89.01%\n",
      "Threshold: 0.65, Accuracy: 90.11%\n",
      "Threshold: 0.70, Accuracy: 91.21%\n",
      "Threshold: 0.75, Accuracy: 91.21%\n",
      "最终准确率: 91.21%, threshold: 0.70\n",
      "AUC Score: 0.7926\n",
      "\n",
      "混淆矩阵:\n",
      "[[79  2]\n",
      " [ 6  4]]\n",
      "\n",
      "分类报告:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.98      0.95        81\n",
      "           1       0.67      0.40      0.50        10\n",
      "\n",
      "    accuracy                           0.91        91\n",
      "   macro avg       0.80      0.69      0.73        91\n",
      "weighted avg       0.90      0.91      0.90        91\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# evaluate saved model\n",
    "print(\"\\n=== 评估保存的最佳模型 ===\")\n",
    "X_train_tensor = torch.tensor(X_train_aug, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train_aug, dtype=torch.float32).view(-1, 1)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test.values, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "# 创建模型\n",
    "best_model = SuperAdvancedClassifier(X_train_tensor.shape[1])\n",
    "best_model.load_state_dict(torch.load(\"model/best_model.pth\"))\n",
    "best_model.eval()\n",
    "with torch.no_grad():\n",
    "    test_outputs = best_model(X_test_tensor)\n",
    "    predicted_probs = torch.sigmoid(test_outputs)\n",
    "\n",
    "    # 动态阈值优化\n",
    "    thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "    best_threshold = 0.5\n",
    "    best_acc = 0\n",
    "    for threshold in thresholds:\n",
    "        predicted = (predicted_probs >= threshold).float()\n",
    "        acc = (predicted.squeeze() == y_test.values).sum() / len(y_test.values) * 100\n",
    "        print(f\"Threshold: {threshold:.2f}, Accuracy: {acc:.2f}%\")\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_threshold = threshold\n",
    "\n",
    "    predicted_final = (predicted_probs >= best_threshold).float()\n",
    "    print(f\"最终准确率: {best_acc:.2f}%, threshold: {best_threshold:.2f}\")\n",
    "    print(f\"AUC Score: {roc_auc_score(y_test.values, predicted_probs.numpy()):.4f}\")\n",
    "    print(\"\\n混淆矩阵:\")\n",
    "    print(confusion_matrix(y_test.values, predicted_final.numpy()))\n",
    "    print(\"\\n分类报告:\")\n",
    "    print(classification_report(y_test.values, predicted_final.numpy()))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
